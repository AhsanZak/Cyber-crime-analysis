{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768a279-a3e1-4d34-ae21-3c6e3537ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud Analysis Notebook\n",
    "# Objective: Investigate cross-bank fraud connections involving a compromised device and user account\n",
    "# Author: [Your Name]\n",
    "# Date: April 28, 2025\n",
    "\n",
    "import pandas as pd\n",
    "import geoip2.database\n",
    "from user_agents import parse\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "NOTEBOOK_DIR = Path(\"notebooks\")\n",
    "OUTPUT_CSV = DATA_DIR / \"enriched_data.csv\"\n",
    "GEOLITE_DB = DATA_DIR / \"GeoLite2-City.mmdb\"\n",
    "\n",
    "# Ensure directories exist\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Excel data into a DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        logger.info(f\"Loaded data from {file_path} with {len(df)} records\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def enrich_ip_data(df: pd.DataFrame, ip_column: str) -> pd.DataFrame:\n",
    "    \"\"\"Enrich IP addresses with country, city, subnet, and timezone, handling multiple IPs.\"\"\"\n",
    "    if not Path(GEOLITE_DB).exists():\n",
    "        logger.error(f\"GeoLite2 database not found at {GEOLITE_DB}\")\n",
    "        return df\n",
    "    \n",
    "    reader = geoip2.database.Reader(GEOLITE_DB)\n",
    "    \n",
    "    def get_ip_info(ip_str):\n",
    "        if pd.isna(ip_str):\n",
    "            return pd.Series({\n",
    "                \"country\": None,\n",
    "                \"city\": None,\n",
    "                \"subnet\": None,\n",
    "                \"timezone\": None\n",
    "            })\n",
    "        # Handle multiple IPs\n",
    "        ip_list = str(ip_str).split(\",\")\n",
    "        # Use the first valid IP for enrichment\n",
    "        for ip in ip_list:\n",
    "            ip = ip.strip()\n",
    "            try:\n",
    "                response = reader.city(ip)\n",
    "                subnet = str(response.traits.network) if response.traits.network else None\n",
    "                return pd.Series({\n",
    "                    \"country\": response.country.name,\n",
    "                    \"city\": response.city.name,\n",
    "                    \"subnet\": subnet,\n",
    "                    \"timezone\": response.location.time_zone\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to enrich IP {ip}: {e}\")\n",
    "        # Return None if all IPs fail\n",
    "        return pd.Series({\n",
    "            \"country\": None,\n",
    "            \"city\": None,\n",
    "            \"subnet\": None,\n",
    "            \"timezone\": None\n",
    "        })\n",
    "    \n",
    "    logger.info(\"Enriching IP data...\")\n",
    "    ip_info = df[ip_column].apply(get_ip_info)\n",
    "    enriched_df = pd.concat([df, ip_info], axis=1)\n",
    "    logger.info(\"IP enrichment completed\")\n",
    "    return enriched_df\n",
    "\n",
    "def enrich_user_agent(df: pd.DataFrame, ua_column: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse User-Agent strings for OS, browser, and device type.\"\"\"\n",
    "    def parse_ua(ua):\n",
    "        if pd.isna(ua):\n",
    "            return pd.Series({\n",
    "                \"os\": None,\n",
    "                \"browser\": None,\n",
    "                \"is_mobile\": None\n",
    "            })\n",
    "        try:\n",
    "            ua_obj = parse(str(ua))\n",
    "            return pd.Series({\n",
    "                \"os\": ua_obj.os.family,\n",
    "                \"browser\": ua_obj.browser.family,\n",
    "                \"is_mobile\": ua_obj.is_mobile\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to parse User-Agent {ua}: {e}\")\n",
    "            return pd.Series({\n",
    "                \"os\": None,\n",
    "                \"browser\": None,\n",
    "                \"is_mobile\": None\n",
    "            })\n",
    "    \n",
    "    logger.info(\"Enriching User-Agent data...\")\n",
    "    ua_info = df[ua_column].apply(parse_ua)\n",
    "    enriched_df = pd.concat([df, ua_info], axis=1)\n",
    "    logger.info(\"User-Agent enrichment completed\")\n",
    "    return enriched_df\n",
    "\n",
    "def find_related_accounts(df: pd.DataFrame, compromised_device: str, compromised_user: str) -> dict:\n",
    "    \"\"\"Find accounts linked to compromised device/user via device parameters or location.\"\"\"\n",
    "    related = {\n",
    "        \"by_device_id\": [],\n",
    "        \"by_device_fingerprint\": [],\n",
    "        \"by_ip\": [],\n",
    "        \"by_location\": []\n",
    "    }\n",
    "    \n",
    "    # Accounts sharing the compromised device\n",
    "    device_accounts = df[df[\"device_id\"] == compromised_device][\"identity\"].unique()\n",
    "    related[\"by_device_id\"] = [acc for acc in device_accounts if acc != \"-\"]\n",
    "    logger.info(f\"Found {len(related['by_device_id'])} accounts linked by device ID\")\n",
    "    \n",
    "    # Accounts with same device fingerprint\n",
    "    try:\n",
    "        device_fingerprint = df[df[\"device_id\"] == compromised_device][\"device_fingerprint\"].iloc[0]\n",
    "        fingerprint_accounts = df[df[\"device_fingerprint\"] == device_fingerprint][\"identity\"].unique()\n",
    "        related[\"by_device_fingerprint\"] = [acc for acc in fingerprint_accounts if acc != \"-\"]\n",
    "        logger.info(f\"Found {len(related['by_device_fingerprint'])} accounts linked by device fingerprint\")\n",
    "    except IndexError:\n",
    "        logger.warning(\"No device fingerprint found for compromised device\")\n",
    "    \n",
    "    # Accounts sharing IPs\n",
    "    compromised_ips = df[df[\"identity\"] == compromised_user][\"ips\"].str.split(\",\", expand=True).stack().str.strip().unique()\n",
    "    ip_accounts = df[df[\"ips\"].str.contains(\"|\".join(compromised_ips), na=False)][\"identity\"].unique()\n",
    "    related[\"by_ip\"] = [acc for acc in ip_accounts if acc != \"-\"]\n",
    "    logger.info(f\"Found {len(related['by_ip'])} accounts linked by IP\")\n",
    "    \n",
    "    # Accounts in same city\n",
    "    try:\n",
    "        compromised_city = df[df[\"identity\"] == compromised_user][\"city\"].iloc[0]\n",
    "        if pd.notna(compromised_city):\n",
    "            location_accounts = df[df[\"city\"] == compromised_city][\"identity\"].unique()\n",
    "            related[\"by_location\"] = [acc for acc in location_accounts if acc != \"-\"]\n",
    "            logger.info(f\"Found {len(related['by_location'])} accounts linked by city\")\n",
    "        else:\n",
    "            logger.warning(\"Compromised user's city is missing\")\n",
    "    except IndexError:\n",
    "        logger.warning(\"No city data found for compromised user\")\n",
    "    \n",
    "    return related\n",
    "\n",
    "def create_network_visualization(df: pd.DataFrame, related_accounts: dict) -> None:\n",
    "    \"\"\"Create a network graph of accounts and devices.\"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes (filter out invalid identities)\n",
    "    for device in df[\"device_id\"].unique():\n",
    "        if pd.notna(device):\n",
    "            G.add_node(device, type=\"device\")\n",
    "    for account in df[\"identity\"].unique():\n",
    "        if pd.notna(account) and account != \"-\":\n",
    "            G.add_node(account, type=\"account\")\n",
    "    \n",
    "    # Add edges\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.notna(row[\"device_id\"]) and pd.notna(row[\"identity\"]) and row[\"identity\"] != \"-\":\n",
    "            G.add_edge(row[\"device_id\"], row[\"identity\"])\n",
    "    \n",
    "    # Highlight compromised nodes\n",
    "    compromised_nodes = [COMPROMISED_DEVICE, COMPROMISED_USER]\n",
    "    node_colors = [\"red\" if node in compromised_nodes else \"blue\" for node in G.nodes]\n",
    "    node_sizes = [1000 if node in compromised_nodes else 500 for node in G.nodes]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        font_size=8,\n",
    "        edge_color=\"gray\"\n",
    "    )\n",
    "    plt.title(\"Network of Devices and User Accounts (Red: Compromised)\")\n",
    "    plt.savefig(NOTEBOOK_DIR / \"network_graph.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    logger.info(\"Network visualization saved\")\n",
    "\n",
    "def create_eda_visualizations(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Generate exploratory data analysis visualizations with counts above bars.\"\"\"\n",
    "    # Bank distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(data=df, x=\"bank\")\n",
    "    plt.title(\"Distribution of Records by Bank\")\n",
    "    plt.xticks(rotation=45)\n",
    "    # Add counts above bars\n",
    "    for p in ax.patches:\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2.,\n",
    "            p.get_height() + 0.5,\n",
    "            f\"{int(p.get_height())}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\"\n",
    "        )\n",
    "    plt.savefig(NOTEBOOK_DIR / \"bank_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Country distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(data=df, x=\"country\")\n",
    "    plt.title(\"Distribution of Records by Country\")\n",
    "    plt.xticks(rotation=45)\n",
    "    # Add counts above bars\n",
    "    for p in ax.patches:\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2.,\n",
    "            p.get_height() + 0.5,\n",
    "            f\"{int(p.get_height())}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\"\n",
    "        )\n",
    "    plt.savefig(NOTEBOOK_DIR / \"country_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Device type distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(data=df, x=\"is_mobile\")\n",
    "    plt.title(\"Distribution of Device Types\")\n",
    "    plt.xticks([0, 1], [\"Desktop\", \"Mobile\"])\n",
    "    # Add counts above bars\n",
    "    for p in ax.patches:\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2.,\n",
    "            p.get_height() + 0.5,\n",
    "            f\"{int(p.get_height())}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\"\n",
    "        )\n",
    "    plt.savefig(NOTEBOOK_DIR / \"device_type_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Missing data analysis\n",
    "    missing_data = df.isnull().sum()\n",
    "    logger.info(f\"Missing data:\\n{missing_data}\")\n",
    "    \n",
    "    # City data check\n",
    "    city_counts = df[\"city\"].value_counts(dropna=False)\n",
    "    logger.info(f\"City distribution:\\n{city_counts}\")\n",
    "\n",
    "# Main analysis\n",
    "COMPROMISED_DEVICE = \"91b12379-8098-457f-a2ad-a94d767797c2\"\n",
    "COMPROMISED_USER = \"0007f265568f1abc1da791e852877df2047b3af9\"\n",
    "\n",
    "# Step 1: Load data\n",
    "df = load_data(DATA_DIR / \"test.xlsx\")\n",
    "if df.empty:\n",
    "    logger.error(\"Failed to load data. Exiting.\")\n",
    "    raise SystemExit(\"Failed to load data.\")\n",
    "\n",
    "# Step 2: Enrich data\n",
    "df = enrich_ip_data(df, \"ips\")\n",
    "df = enrich_user_agent(df, \"browser\")\n",
    "\n",
    "# Step 3: Find related accounts\n",
    "related_accounts = find_related_accounts(df, COMPROMISED_DEVICE, COMPROMISED_USER)\n",
    "print(\"Related Accounts:\")\n",
    "for key, accounts in related_accounts.items():\n",
    "    print(f\"{key}: {accounts}\")\n",
    "\n",
    "# Step 4: Visualizations\n",
    "create_network_visualization(df, related_accounts)\n",
    "create_eda_visualizations(df)\n",
    "\n",
    "# Step 5: Save enriched data\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "logger.info(f\"Enriched data saved to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74e352-0233-4060-86d0-693e4d7278df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
